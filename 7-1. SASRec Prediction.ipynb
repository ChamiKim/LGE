{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d77be0bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model.sasrec import SASRecModel\n",
    "from trainers import Trainer\n",
    "from utils import EarlyStopping, check_path, set_seed, set_logger\n",
    "from dataset import get_seq_dic, get_dataloder, get_rating_matrix\n",
    "\n",
    "# Set up arguments\n",
    "class Args:\n",
    "    data_dir = \"./data/\"\n",
    "    output_dir = \"output/\"\n",
    "    data_name = \"input_search_augmented_final_20241127\"\n",
    "    do_eval = False\n",
    "    load_model = None\n",
    "    train_name = \"test_model\"\n",
    "    num_items = 10\n",
    "    num_users = 10\n",
    "    lr = 0.001\n",
    "    batch_size = 256\n",
    "    epochs = 10\n",
    "    no_cuda = False\n",
    "    log_freq = 1\n",
    "    patience = 2\n",
    "    num_workers = 0  # Set num_workers to 0 to avoid BrokenPipeError on Windows\n",
    "    seed = 42\n",
    "    weight_decay = 0.0\n",
    "    adam_beta1 = 0.9\n",
    "    adam_beta2 = 0.999\n",
    "    gpu_id = \"0\"\n",
    "    variance = 5\n",
    "    model_type = 'bert4rec'\n",
    "#     model_type = 'sasrec_model'\n",
    "    max_seq_length = 50\n",
    "    hidden_size = 256\n",
    "    num_hidden_layers = 2\n",
    "    hidden_act = \"gelu\"\n",
    "    num_attention_heads = 2\n",
    "    attention_probs_dropout_prob = 0.5\n",
    "    hidden_dropout_prob = 0.5\n",
    "    initializer_range = 0.02\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bc177bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 12:30:44,466 - <__main__.Args object at 0x7fa09455d7d0>\n",
      "2024-11-27 12:30:44,597 - SASRecModel(\n",
      "  (item_embeddings): Embedding(30091, 256, padding_idx=0)\n",
      "  (position_embeddings): Embedding(50, 256)\n",
      "  (LayerNorm): LayerNorm()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (item_encoder): TransformerEncoder(\n",
      "    (blocks): ModuleList(\n",
      "      (0): TransformerBlock(\n",
      "        (layer): MultiHeadAttention(\n",
      "          (query): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (key): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (value): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (attn_dropout): Dropout(p=0.5, inplace=False)\n",
      "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "          (out_dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (feed_forward): FeedForward(\n",
      "          (dense_1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (dense_2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (LayerNorm): LayerNorm()\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): TransformerBlock(\n",
      "        (layer): MultiHeadAttention(\n",
      "          (query): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (key): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (value): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (attn_dropout): Dropout(p=0.5, inplace=False)\n",
      "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
      "          (out_dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (feed_forward): FeedForward(\n",
      "          (dense_1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (dense_2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (LayerNorm): LayerNorm()\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "2024-11-27 12:30:50,263 - Total Parameters: 9296128\n",
      "Mode_train:0: 100%|| 8325/8325 [10:02<00:00, 13.82it/s]\n",
      "2024-11-27 12:40:55,113 - {'epoch': 0, 'rec_loss': '0.4151'}\n",
      "Mode_test:0: 100%|| 1200/1200 [02:59<00:00,  6.68it/s]\n",
      "2024-11-27 12:44:13,448 - {'Epoch': 0, 'HR@5': '0.0449', 'NDCG@5': '0.0307', 'HR@10': '0.0675', 'NDCG@10': '0.0379', 'HR@20': '0.1019', 'NDCG@20': '0.0466'}\n",
      "2024-11-27 12:44:13,459 - Validation score increased.  Saving model ...\n",
      "Mode_train:1: 100%|| 8325/8325 [10:00<00:00, 13.86it/s]\n",
      "2024-11-27 12:54:14,132 - {'epoch': 1, 'rec_loss': '0.2665'}\n",
      "Mode_test:1: 100%|| 1200/1200 [03:02<00:00,  6.56it/s]\n",
      "2024-11-27 12:57:35,904 - {'Epoch': 1, 'HR@5': '0.0682', 'NDCG@5': '0.0489', 'HR@10': '0.0963', 'NDCG@10': '0.0579', 'HR@20': '0.1361', 'NDCG@20': '0.0679'}\n",
      "2024-11-27 12:57:35,905 - Validation score increased.  Saving model ...\n",
      "Mode_train:2: 100%|| 8325/8325 [09:59<00:00, 13.89it/s]\n",
      "2024-11-27 13:07:35,268 - {'epoch': 2, 'rec_loss': '0.2248'}\n",
      "Mode_test:2: 100%|| 1200/1200 [02:57<00:00,  6.75it/s]\n",
      "2024-11-27 13:10:52,140 - {'Epoch': 2, 'HR@5': '0.0798', 'NDCG@5': '0.0570', 'HR@10': '0.1105', 'NDCG@10': '0.0669', 'HR@20': '0.1517', 'NDCG@20': '0.0773'}\n",
      "2024-11-27 13:10:52,147 - Validation score increased.  Saving model ...\n",
      "Mode_train:3: 100%|| 8325/8325 [09:59<00:00, 13.90it/s]\n",
      "2024-11-27 13:20:51,385 - {'epoch': 3, 'rec_loss': '0.2067'}\n",
      "Mode_test:3: 100%|| 1200/1200 [02:58<00:00,  6.72it/s]\n",
      "2024-11-27 13:24:08,940 - {'Epoch': 3, 'HR@5': '0.0870', 'NDCG@5': '0.0623', 'HR@10': '0.1200', 'NDCG@10': '0.0729', 'HR@20': '0.1670', 'NDCG@20': '0.0847'}\n",
      "2024-11-27 13:24:08,950 - Validation score increased.  Saving model ...\n",
      "Mode_train:4: 100%|| 8325/8325 [09:58<00:00, 13.91it/s]\n",
      "2024-11-27 13:34:07,491 - {'epoch': 4, 'rec_loss': '0.1951'}\n",
      "Mode_test:4: 100%|| 1200/1200 [02:49<00:00,  7.10it/s]\n",
      "2024-11-27 13:37:15,621 - {'Epoch': 4, 'HR@5': '0.0909', 'NDCG@5': '0.0652', 'HR@10': '0.1277', 'NDCG@10': '0.0771', 'HR@20': '0.1815', 'NDCG@20': '0.0906'}\n",
      "2024-11-27 13:37:15,628 - Validation score increased.  Saving model ...\n",
      "Mode_train:5: 100%|| 8325/8325 [09:59<00:00, 13.90it/s]\n",
      "2024-11-27 13:47:14,788 - {'epoch': 5, 'rec_loss': '0.1873'}\n",
      "Mode_test:5: 100%|| 1200/1200 [02:58<00:00,  6.74it/s]\n",
      "2024-11-27 13:50:31,863 - {'Epoch': 5, 'HR@5': '0.0954', 'NDCG@5': '0.0674', 'HR@10': '0.1318', 'NDCG@10': '0.0792', 'HR@20': '0.1805', 'NDCG@20': '0.0914'}\n",
      "2024-11-27 13:50:31,865 - Validation score increased.  Saving model ...\n",
      "Mode_train:6: 100%|| 8325/8325 [09:59<00:00, 13.89it/s]\n",
      "2024-11-27 14:00:31,349 - {'epoch': 6, 'rec_loss': '0.1810'}\n",
      "Mode_test:6: 100%|| 1200/1200 [02:49<00:00,  7.07it/s]\n",
      "2024-11-27 14:03:40,141 - {'Epoch': 6, 'HR@5': '0.0970', 'NDCG@5': '0.0692', 'HR@10': '0.1342', 'NDCG@10': '0.0812', 'HR@20': '0.1848', 'NDCG@20': '0.0939'}\n",
      "2024-11-27 14:03:40,145 - Validation score increased.  Saving model ...\n",
      "Mode_train:7: 100%|| 8325/8325 [09:58<00:00, 13.90it/s]\n",
      "2024-11-27 14:13:39,235 - {'epoch': 7, 'rec_loss': '0.1768'}\n",
      "Mode_test:7: 100%|| 1200/1200 [02:49<00:00,  7.09it/s]\n",
      "2024-11-27 14:16:47,298 - {'Epoch': 7, 'HR@5': '0.0973', 'NDCG@5': '0.0693', 'HR@10': '0.1368', 'NDCG@10': '0.0820', 'HR@20': '0.1900', 'NDCG@20': '0.0954'}\n",
      "2024-11-27 14:16:47,305 - Validation score increased.  Saving model ...\n",
      "Mode_train:8: 100%|| 8325/8325 [09:58<00:00, 13.90it/s]\n",
      "2024-11-27 14:26:46,329 - {'epoch': 8, 'rec_loss': '0.1734'}\n",
      "Mode_test:8: 100%|| 1200/1200 [02:47<00:00,  7.16it/s]\n",
      "2024-11-27 14:29:53,011 - {'Epoch': 8, 'HR@5': '0.0987', 'NDCG@5': '0.0699', 'HR@10': '0.1374', 'NDCG@10': '0.0823', 'HR@20': '0.1951', 'NDCG@20': '0.0968'}\n",
      "2024-11-27 14:29:53,017 - Validation score increased.  Saving model ...\n",
      "Mode_train:9: 100%|| 8325/8325 [09:59<00:00, 13.89it/s]\n",
      "2024-11-27 14:39:52,474 - {'epoch': 9, 'rec_loss': '0.1705'}\n",
      "Mode_test:9: 100%|| 1200/1200 [02:40<00:00,  7.46it/s]\n",
      "2024-11-27 14:42:52,436 - {'Epoch': 9, 'HR@5': '0.1001', 'NDCG@5': '0.0709', 'HR@10': '0.1392', 'NDCG@10': '0.0835', 'HR@20': '0.1926', 'NDCG@20': '0.0969'}\n",
      "2024-11-27 14:42:52,438 - Validation score increased.  Saving model ...\n",
      "2024-11-27 14:42:52,530 - ---------------Test Score---------------\n",
      "Mode_test:0: 100%|| 1200/1200 [02:40<00:00,  7.49it/s]\n",
      "2024-11-27 14:45:51,758 - {'Epoch': 0, 'HR@5': '0.0901', 'NDCG@5': '0.0631', 'HR@10': '0.1264', 'NDCG@10': '0.0748', 'HR@20': '0.1762', 'NDCG@20': '0.0873'}\n",
      "2024-11-27 14:45:51,763 - test_model\n",
      "2024-11-27 14:45:51,764 - {'Epoch': 0, 'HR@5': '0.0901', 'NDCG@5': '0.0631', 'HR@10': '0.1264', 'NDCG@10': '0.0748', 'HR@20': '0.1762', 'NDCG@20': '0.0873'}\n"
     ]
    }
   ],
   "source": [
    "# model train\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize logger\n",
    "    log_path = os.path.join(args.output_dir, args.train_name + '.log')\n",
    "    logger = set_logger(log_path)\n",
    "\n",
    "    # Set seed for reproducibility\n",
    "    set_seed(args.seed)\n",
    "\n",
    "    # Create output directory if not exists\n",
    "    check_path(args.output_dir)\n",
    "\n",
    "    # Set CUDA environment\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu_id\n",
    "    args.cuda_condition = torch.cuda.is_available() and not args.no_cuda\n",
    "\n",
    "    # Load data\n",
    "    seq_dic, max_item, num_users = get_seq_dic(args)\n",
    "    args.item_size = max_item + 1\n",
    "    args.num_users = num_users + 1\n",
    "\n",
    "    # Prepare checkpoint paths\n",
    "    args.checkpoint_path = os.path.join(args.output_dir, args.train_name + '.pt')\n",
    "    args.same_target_path = os.path.join(args.data_dir, args.data_name+'_same_target.npy')\n",
    "\n",
    "    # Load dataloaders\n",
    "    train_dataloader, eval_dataloader, test_dataloader = get_dataloder(args, seq_dic)\n",
    "\n",
    "    # Initialize and log model\n",
    "    logger.info(str(args))\n",
    "    model = SASRecModel(args=args)\n",
    "    logger.info(model)\n",
    "\n",
    "    # Initialize trainer\n",
    "    trainer = Trainer(model, train_dataloader, eval_dataloader, test_dataloader, args, logger)\n",
    "\n",
    "    # Generate rating matrices for evaluation\n",
    "    args.valid_rating_matrix, args.test_rating_matrix = get_rating_matrix(args.data_name, seq_dic, max_item)\n",
    "\n",
    "    # Training and evaluation\n",
    "    if args.do_eval:\n",
    "        if args.load_model is None:\n",
    "            logger.info(f\"No model input!\")\n",
    "            exit(0)\n",
    "        else:\n",
    "            args.checkpoint_path = os.path.join(args.output_dir, args.load_model + '.pt')\n",
    "            trainer.load(args.checkpoint_path)\n",
    "            logger.info(f\"Load model from {args.checkpoint_path} for test!\")\n",
    "            scores, result_info = trainer.test(0)\n",
    "    else:\n",
    "        early_stopping = EarlyStopping(args.checkpoint_path, logger=logger, patience=args.patience, verbose=True)\n",
    "        for epoch in range(args.epochs):\n",
    "            trainer.train(epoch)\n",
    "            scores, _ = trainer.valid(epoch)\n",
    "            # evaluate on MRR\n",
    "            early_stopping(np.array(scores[-1:]), trainer.model)\n",
    "            if early_stopping.early_stop:\n",
    "                logger.info(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "        logger.info(\"---------------Test Score---------------\")\n",
    "        trainer.model.load_state_dict(torch.load(args.checkpoint_path))\n",
    "        scores, result_info = trainer.test(0)\n",
    "\n",
    "    logger.info(args.train_name)\n",
    "    logger.info(result_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "935b0d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model save\n",
    "torch.save(model, \"bert4rec_20241127.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "936a18d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10356/1888757279.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"/data/log-data-2024/yh/LLM_EB/src_dp/output/llmeb.pt\", map_location=device))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for SASRecModel:\n\tMissing key(s) in state_dict: \"item_embeddings.weight\", \"position_embeddings.weight\", \"LayerNorm.weight\", \"LayerNorm.bias\", \"item_encoder.blocks.0.layer.query.weight\", \"item_encoder.blocks.0.layer.query.bias\", \"item_encoder.blocks.0.layer.key.weight\", \"item_encoder.blocks.0.layer.key.bias\", \"item_encoder.blocks.0.layer.value.weight\", \"item_encoder.blocks.0.layer.value.bias\", \"item_encoder.blocks.0.layer.dense.weight\", \"item_encoder.blocks.0.layer.dense.bias\", \"item_encoder.blocks.0.layer.LayerNorm.weight\", \"item_encoder.blocks.0.layer.LayerNorm.bias\", \"item_encoder.blocks.0.feed_forward.dense_1.weight\", \"item_encoder.blocks.0.feed_forward.dense_1.bias\", \"item_encoder.blocks.0.feed_forward.dense_2.weight\", \"item_encoder.blocks.0.feed_forward.dense_2.bias\", \"item_encoder.blocks.0.feed_forward.LayerNorm.weight\", \"item_encoder.blocks.0.feed_forward.LayerNorm.bias\", \"item_encoder.blocks.1.layer.query.weight\", \"item_encoder.blocks.1.layer.query.bias\", \"item_encoder.blocks.1.layer.key.weight\", \"item_encoder.blocks.1.layer.key.bias\", \"item_encoder.blocks.1.layer.value.weight\", \"item_encoder.blocks.1.layer.value.bias\", \"item_encoder.blocks.1.layer.dense.weight\", \"item_encoder.blocks.1.layer.dense.bias\", \"item_encoder.blocks.1.layer.LayerNorm.weight\", \"item_encoder.blocks.1.layer.LayerNorm.bias\", \"item_encoder.blocks.1.feed_forward.dense_1.weight\", \"item_encoder.blocks.1.feed_forward.dense_1.bias\", \"item_encoder.blocks.1.feed_forward.dense_2.weight\", \"item_encoder.blocks.1.feed_forward.dense_2.bias\", \"item_encoder.blocks.1.feed_forward.LayerNorm.weight\", \"item_encoder.blocks.1.feed_forward.LayerNorm.bias\". \n\tUnexpected key(s) in state_dict: \"module.item_embeddings.weight\", \"module.position_embeddings.weight\", \"module.LayerNorm.weight\", \"module.LayerNorm.bias\", \"module.item_encoder.blocks.0.layer.query.weight\", \"module.item_encoder.blocks.0.layer.query.bias\", \"module.item_encoder.blocks.0.layer.key.weight\", \"module.item_encoder.blocks.0.layer.key.bias\", \"module.item_encoder.blocks.0.layer.value.weight\", \"module.item_encoder.blocks.0.layer.value.bias\", \"module.item_encoder.blocks.0.layer.dense.weight\", \"module.item_encoder.blocks.0.layer.dense.bias\", \"module.item_encoder.blocks.0.layer.LayerNorm.weight\", \"module.item_encoder.blocks.0.layer.LayerNorm.bias\", \"module.item_encoder.blocks.0.feed_forward.dense_1.weight\", \"module.item_encoder.blocks.0.feed_forward.dense_1.bias\", \"module.item_encoder.blocks.0.feed_forward.dense_2.weight\", \"module.item_encoder.blocks.0.feed_forward.dense_2.bias\", \"module.item_encoder.blocks.0.feed_forward.LayerNorm.weight\", \"module.item_encoder.blocks.0.feed_forward.LayerNorm.bias\", \"module.item_encoder.blocks.1.layer.query.weight\", \"module.item_encoder.blocks.1.layer.query.bias\", \"module.item_encoder.blocks.1.layer.key.weight\", \"module.item_encoder.blocks.1.layer.key.bias\", \"module.item_encoder.blocks.1.layer.value.weight\", \"module.item_encoder.blocks.1.layer.value.bias\", \"module.item_encoder.blocks.1.layer.dense.weight\", \"module.item_encoder.blocks.1.layer.dense.bias\", \"module.item_encoder.blocks.1.layer.LayerNorm.weight\", \"module.item_encoder.blocks.1.layer.LayerNorm.bias\", \"module.item_encoder.blocks.1.feed_forward.dense_1.weight\", \"module.item_encoder.blocks.1.feed_forward.dense_1.bias\", \"module.item_encoder.blocks.1.feed_forward.dense_2.weight\", \"module.item_encoder.blocks.1.feed_forward.dense_2.bias\", \"module.item_encoder.blocks.1.feed_forward.LayerNorm.weight\", \"module.item_encoder.blocks.1.feed_forward.LayerNorm.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m SASRecModel(args)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Load the state dictionary into the model\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/data/log-data-2024/yh/LLM_EB/src_dp/output/llmeb.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Move the model to the device (CPU or GPU)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/llmrs/lib/python3.10/site-packages/torch/nn/modules/module.py:2215\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2210\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2211\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2212\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2216\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SASRecModel:\n\tMissing key(s) in state_dict: \"item_embeddings.weight\", \"position_embeddings.weight\", \"LayerNorm.weight\", \"LayerNorm.bias\", \"item_encoder.blocks.0.layer.query.weight\", \"item_encoder.blocks.0.layer.query.bias\", \"item_encoder.blocks.0.layer.key.weight\", \"item_encoder.blocks.0.layer.key.bias\", \"item_encoder.blocks.0.layer.value.weight\", \"item_encoder.blocks.0.layer.value.bias\", \"item_encoder.blocks.0.layer.dense.weight\", \"item_encoder.blocks.0.layer.dense.bias\", \"item_encoder.blocks.0.layer.LayerNorm.weight\", \"item_encoder.blocks.0.layer.LayerNorm.bias\", \"item_encoder.blocks.0.feed_forward.dense_1.weight\", \"item_encoder.blocks.0.feed_forward.dense_1.bias\", \"item_encoder.blocks.0.feed_forward.dense_2.weight\", \"item_encoder.blocks.0.feed_forward.dense_2.bias\", \"item_encoder.blocks.0.feed_forward.LayerNorm.weight\", \"item_encoder.blocks.0.feed_forward.LayerNorm.bias\", \"item_encoder.blocks.1.layer.query.weight\", \"item_encoder.blocks.1.layer.query.bias\", \"item_encoder.blocks.1.layer.key.weight\", \"item_encoder.blocks.1.layer.key.bias\", \"item_encoder.blocks.1.layer.value.weight\", \"item_encoder.blocks.1.layer.value.bias\", \"item_encoder.blocks.1.layer.dense.weight\", \"item_encoder.blocks.1.layer.dense.bias\", \"item_encoder.blocks.1.layer.LayerNorm.weight\", \"item_encoder.blocks.1.layer.LayerNorm.bias\", \"item_encoder.blocks.1.feed_forward.dense_1.weight\", \"item_encoder.blocks.1.feed_forward.dense_1.bias\", \"item_encoder.blocks.1.feed_forward.dense_2.weight\", \"item_encoder.blocks.1.feed_forward.dense_2.bias\", \"item_encoder.blocks.1.feed_forward.LayerNorm.weight\", \"item_encoder.blocks.1.feed_forward.LayerNorm.bias\". \n\tUnexpected key(s) in state_dict: \"module.item_embeddings.weight\", \"module.position_embeddings.weight\", \"module.LayerNorm.weight\", \"module.LayerNorm.bias\", \"module.item_encoder.blocks.0.layer.query.weight\", \"module.item_encoder.blocks.0.layer.query.bias\", \"module.item_encoder.blocks.0.layer.key.weight\", \"module.item_encoder.blocks.0.layer.key.bias\", \"module.item_encoder.blocks.0.layer.value.weight\", \"module.item_encoder.blocks.0.layer.value.bias\", \"module.item_encoder.blocks.0.layer.dense.weight\", \"module.item_encoder.blocks.0.layer.dense.bias\", \"module.item_encoder.blocks.0.layer.LayerNorm.weight\", \"module.item_encoder.blocks.0.layer.LayerNorm.bias\", \"module.item_encoder.blocks.0.feed_forward.dense_1.weight\", \"module.item_encoder.blocks.0.feed_forward.dense_1.bias\", \"module.item_encoder.blocks.0.feed_forward.dense_2.weight\", \"module.item_encoder.blocks.0.feed_forward.dense_2.bias\", \"module.item_encoder.blocks.0.feed_forward.LayerNorm.weight\", \"module.item_encoder.blocks.0.feed_forward.LayerNorm.bias\", \"module.item_encoder.blocks.1.layer.query.weight\", \"module.item_encoder.blocks.1.layer.query.bias\", \"module.item_encoder.blocks.1.layer.key.weight\", \"module.item_encoder.blocks.1.layer.key.bias\", \"module.item_encoder.blocks.1.layer.value.weight\", \"module.item_encoder.blocks.1.layer.value.bias\", \"module.item_encoder.blocks.1.layer.dense.weight\", \"module.item_encoder.blocks.1.layer.dense.bias\", \"module.item_encoder.blocks.1.layer.LayerNorm.weight\", \"module.item_encoder.blocks.1.layer.LayerNorm.bias\", \"module.item_encoder.blocks.1.feed_forward.dense_1.weight\", \"module.item_encoder.blocks.1.feed_forward.dense_1.bias\", \"module.item_encoder.blocks.1.feed_forward.dense_2.weight\", \"module.item_encoder.blocks.1.feed_forward.dense_2.bias\", \"module.item_encoder.blocks.1.feed_forward.LayerNorm.weight\", \"module.item_encoder.blocks.1.feed_forward.LayerNorm.bias\". "
     ]
    }
   ],
   "source": [
    "# # Import your model class (make sure to import the correct one)\n",
    "# from model.sasrec import SASRecModel  # or import the appropriate model class\n",
    "\n",
    "# # Instantiate the model\n",
    "# model = SASRecModel(args)\n",
    "\n",
    "# # Load the state dictionary into the model\n",
    "# model.load_state_dict(torch.load(\"/data/log-data-2024/yh/LLM_EB/src_dp/output/llmeb.pt\", map_location=device))\n",
    "\n",
    "# # Move the model to the device (CPU or GPU)\n",
    "# model = model.to(device)\n",
    "\n",
    "# # Now you can call your predict function\n",
    "# pred = predict(model, ids, device).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61a7880",
   "metadata": {},
   "source": [
    "## prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f4281d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# model = torch.load(\"bert4rec.pt\")\n",
    "model = torch.load(\"bert4rec_20241127.pt\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "134f4c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standalone predict function\n",
    "def predict(model, input_ids, device):\n",
    "    model.eval()\n",
    "    input_ids = torch.tensor(input_ids, dtype=torch.long).to(device)\n",
    "    with torch.no_grad():\n",
    "        recommend_output = model.forward(input_ids, all_sequence_output=False)\n",
    "        recommend_output = recommend_output[:, -1, :]  # Last item in the sequence\n",
    "\n",
    "        test_item_emb = model.item_embeddings.weight\n",
    "        rating_pred = torch.matmul(recommend_output, test_item_emb.transpose(0, 1))\n",
    "        rating_pred = rating_pred.cpu().data.numpy().copy()\n",
    "\n",
    "        top20_indices = np.argpartition(rating_pred, -40)[:, -40:]\n",
    "        arr_ind = rating_pred[np.arange(len(rating_pred))[:, None], top20_indices]\n",
    "        arr_ind_argsort = np.argsort(arr_ind)[np.arange(len(rating_pred)), ::-1]\n",
    "        top20_indices = top20_indices[np.arange(len(rating_pred))[:, None], arr_ind_argsort]\n",
    "\n",
    "    return top20_indices\n",
    "\n",
    "def get_attention_weight(model, input_ids, device):\n",
    "    model.eval()\n",
    "    input_ids = torch.tensor(input_ids, dtype=torch.long).to(device)\n",
    "    with torch.no_grad():\n",
    "        recommend_output = model.forward(input_ids, all_sequence_output=False)\n",
    "        recommend_output = recommend_output[:, -1, :]  # Last item in the sequence\n",
    "\n",
    "        test_item_emb = model.item_embeddings.weight\n",
    "    \n",
    "    return test_item_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36355ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 307010/307010 [00:01<00:00, 191038.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.369053125305365 24.01168706773932 3 702\n"
     ]
    }
   ],
   "source": [
    "with open('/data/log-data-2024/SASRec/BSARec/src/data/input_search_augmented_final_20241127.txt', 'r') as f:\n",
    "    input_data = f.readlines()\n",
    "\n",
    "input_ids = []\n",
    "for i in input_data:\n",
    "    temp = [int(w) for w in i.replace(\"\\n\", \"\").split()[1:]]\n",
    "    while len(temp) < 51:\n",
    "        temp.insert(0, 0)\n",
    "    input_ids.append(temp)\n",
    "    \n",
    "confirm = []\n",
    "for i in tqdm(input_ids):\n",
    "    temp = []\n",
    "    for w in i:\n",
    "        if w != 0:\n",
    "            temp.append(w)\n",
    "    confirm.append(temp)\n",
    "\n",
    "length = [len(i) for i in confirm]\n",
    "print(np.mean(length), np.std(length), np.min(length), np.max(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a629366",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanyang-user/.local/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "input_ids = [seq[-50:] for seq in input_ids]\n",
    "\n",
    "label = [i[-1] for i in input_ids]\n",
    "input_ids = [i[:-1] for i in input_ids]\n",
    "        \n",
    "\n",
    "lab = label[:1000]\n",
    "ids = input_ids[:1000]\n",
    "\n",
    "ids = torch.tensor(ids, dtype=torch.long).to(device)\n",
    "\n",
    "pred = predict(model, ids, device).tolist() # SASRec 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d496e2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = ids.cpu().tolist()\n",
    "\n",
    "cnt = []\n",
    "for i in ids:\n",
    "    for w in i:\n",
    "        cnt.append(w)\n",
    "        \n",
    "cnt = dict(Counter(cnt))\n",
    "cnt = pd.DataFrame({\"token\" : cnt.keys(), \"count\" : cnt.values()})\n",
    "cnt = cnt.sort_values(by = \"count\", ascending = False).reset_index(drop = True).loc[1:21]\n",
    "cnt = list(cnt[\"token\"])\n",
    "\n",
    "cnt = [cnt for i in range(len(lab))] # PopRec 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f8050a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # llm for embeddings\n",
    "# lr = pd.read_csv(\"/data/log-data-2024/yh/LLM_RS/top_prediction.csv\")\n",
    "# lr = lr.fillna(1)\n",
    "# lr_pred = []\n",
    "# for i in lr.index:\n",
    "#     lr_pred.append([int(w) for w in list(lr.loc[i][lr.columns[1:]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8906ae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hr_at_k(recommendations, true_labels, k=20):\n",
    "    score = 0\n",
    "    recommendations = [i[:k] for i in recommendations]\n",
    "    for a, i in enumerate(true_labels):\n",
    "        if i in recommendations[a]:\n",
    "            score += 1\n",
    "    return score/len(true_labels)\n",
    "\n",
    "def precision_at_k(recommendations, true_labels, k=20):\n",
    "    precision_scores = []\n",
    "    \n",
    "    for user_recommendations, true_label in zip(recommendations, true_labels):\n",
    "        # 추천된 상위 20개 중 실제 정답이 있는지 확인\n",
    "        hits = 1 if true_label in user_recommendations[:k] else 0\n",
    "        \n",
    "        # Precision은 정답이 있으면 1 / k, 없으면 0\n",
    "        precision = hits / k\n",
    "        precision_scores.append(precision)\n",
    "    \n",
    "    # 모든 사용자에 대한 평균 Precision을 반환\n",
    "    return sum(precision_scores) / len(precision_scores)\n",
    "\n",
    "def recall_at_k(recommendations, true_labels, k=20):\n",
    "    recall_scores = []\n",
    "    \n",
    "    for user_recommendations, true_label in zip(recommendations, true_labels):\n",
    "        # 추천된 상위 k개 중 실제 정답이 있는지 확인\n",
    "        hits = 1 if true_label in user_recommendations[:k] else 0\n",
    "        \n",
    "        # Recall은 정답이 있으면 1, 없으면 0\n",
    "        recall = hits\n",
    "        recall_scores.append(recall)\n",
    "    \n",
    "    # 모든 사용자에 대한 평균 Recall을 반환\n",
    "    return sum(recall_scores) / len(recall_scores)\n",
    "\n",
    "def total_print(k):\n",
    "    print(\"SASRec HR@{}: \".format(k), round(hr_at_k(pred, lab, k = k), 3))\n",
    "#     print(\"LLM as RS HR@{}: \".format(k), round(hr_at_k(lr_pred, lab, k = k), 3))\n",
    "    print(\"PopRec HR@{}: \".format(k), round(hr_at_k(cnt, lab, k = k), 3))\n",
    "    print(\"\")\n",
    "    print(\"SASRec precision@{}: \".format(k), round(precision_at_k(pred, lab, k = k), 3))\n",
    "#     print(\"LLM as RS precision@{}: \".format(k), round(precision_at_k(lr_pred, lab, k = k), 3))\n",
    "    print(\"PopRec precision@{}: \".format(k), round(precision_at_k(cnt, lab, k = k), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fe0d22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SASRec HR@1:  0.117\n",
      "PopRec HR@1:  0.017\n",
      "\n",
      "SASRec precision@1:  0.117\n",
      "PopRec precision@1:  0.017\n",
      "\n",
      "SASRec HR@3:  0.162\n",
      "PopRec HR@3:  0.054\n",
      "\n",
      "SASRec precision@3:  0.054\n",
      "PopRec precision@3:  0.018\n",
      "\n",
      "SASRec HR@5:  0.201\n",
      "PopRec HR@5:  0.065\n",
      "\n",
      "SASRec precision@5:  0.04\n",
      "PopRec precision@5:  0.013\n",
      "\n",
      "SASRec HR@10:  0.228\n",
      "PopRec HR@10:  0.102\n",
      "\n",
      "SASRec precision@10:  0.023\n",
      "PopRec precision@10:  0.01\n",
      "\n",
      "SASRec HR@15:  0.263\n",
      "PopRec HR@15:  0.118\n",
      "\n",
      "SASRec precision@15:  0.018\n",
      "PopRec precision@15:  0.008\n",
      "\n",
      "SASRec HR@20:  0.292\n",
      "PopRec HR@20:  0.147\n",
      "\n",
      "SASRec precision@20:  0.015\n",
      "PopRec precision@20:  0.007\n"
     ]
    }
   ],
   "source": [
    "total_print(1)\n",
    "print(\"\")\n",
    "total_print(3)\n",
    "print(\"\")\n",
    "total_print(5)\n",
    "print(\"\")\n",
    "total_print(10)\n",
    "print(\"\")\n",
    "total_print(15)\n",
    "print(\"\")\n",
    "total_print(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e425990",
   "metadata": {},
   "source": [
    "# Prediction for new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e2e196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "df = pd.read_csv(\"/data/log-data-2024/2.sequence_generate_ksc/data/sequence_device_match_241127.csv\")\n",
    "cf = pd.read_csv(\"/data/log-data-2024/20241127_Final/input_search_final_20241127.txt\", sep = \"\\t\", header = None)\n",
    "df = pd.concat([df, cf], axis = 1)\n",
    "\n",
    "with open(file= '/data/log-data-2024/20241123_Final/match_dict_final.pickle', mode='rb') as f:\n",
    "    dic1 = pickle.load(f)\n",
    "\n",
    "with open(file= '/data/log-data-2024/20241123_Final/match_dict_final2.pickle', mode='rb') as f:\n",
    "    dic2 = pickle.load(f)\n",
    "    \n",
    "samp = list(pd.read_csv(\"/data/log-data-2024/20241127_Final/8man_sample_20241127.csv\")[\"treatment1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2269c0ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 73505/73505 [00:20<00:00, 3616.25it/s]\n"
     ]
    }
   ],
   "source": [
    "rev = dict(zip(list(dic1.values()), list(dic1.keys())))\n",
    "dic = {}\n",
    "for i in dic2:\n",
    "    try:\n",
    "        dic[rev[i]] = dic2[i]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "df[\"use\"] = [1 if i in samp else 0 for i in tqdm(df[\"device_id\"])]\n",
    "df = df[df[\"use\"] == 1]\n",
    "df = df.drop_duplicates(subset = 'device_id').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da9fe0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LLM as RS를 위한 처리\n",
    "# convert = {}\n",
    "# for i in dic1:\n",
    "#     try:\n",
    "#         convert[i] = dic2[dic1[i]]\n",
    "#     except:\n",
    "#         pass\n",
    "\n",
    "# df = df[[\"device_id\", 0]].reset_index(drop = True)\n",
    "# df[1] = [i.split()[1:] for i in df[0]]\n",
    "\n",
    "# rev = dict(zip(list(dic2.values()), list(dic2.keys())))\n",
    "\n",
    "# res = []\n",
    "# for i in df[1]:\n",
    "#     temp = []\n",
    "#     for w in i:\n",
    "#         try:\n",
    "#             num = convert[int(w)] \n",
    "#             temp.append(num+ \". \" + rev[num])\n",
    "#         except:\n",
    "#             pass\n",
    "#     res.append(temp)\n",
    "# df[\"llmasrs\"] = res\n",
    "\n",
    "# df.to_csv(\"/data/log-data-2024/2.sequence_generate_ksc/data/prediction_set_for_LLMasRS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c1623e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_file_path = \"/data/log-data-2024/SASRec/BSARec/src/data/input_search_prediction_final.txt\"\n",
    "# with open(input_file_path, 'r') as f:\n",
    "#     input_data = f.readlines()\n",
    "\n",
    "input_data = []\n",
    "\n",
    "for i in df[0]:\n",
    "    temp = []\n",
    "    t = i.split()[1:]\n",
    "    for w in t:\n",
    "#         temp.append(dic[int(w)])\n",
    "        try:\n",
    "            temp.append(str(w))\n",
    "        except:\n",
    "            pass\n",
    "    input_data.append(\" \".join(temp))\n",
    "\n",
    "input_ids = []\n",
    "for line in input_data:\n",
    "    items = list(map(int, line.strip().split()))\n",
    "    pad_len = args.max_seq_length - len(items)\n",
    "    input_ids.append([0] * pad_len + items)\n",
    "    \n",
    "# confirm = []\n",
    "# for i in tqdm(input_ids):\n",
    "#     temp = []\n",
    "#     for w in i:\n",
    "#         if w != 0:\n",
    "#             temp.append(w)\n",
    "#     confirm.append(temp)\n",
    "\n",
    "# length = [len(i) for i in confirm]\n",
    "# print(np.mean(length), np.std(length), np.min(length), np.max(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2a9838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = []\n",
    "for i in input_ids:\n",
    "    temp = i\n",
    "    while len(temp) > 50:\n",
    "        temp = temp[1:]\n",
    "    ii.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a610c66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "for i in range(20):\n",
    "    pred = pred + predict(model, ii[i*1000:(i+1)*1000], device).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "110228a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = pd.DataFrame({\"treatment1\" : df[\"device_id\"], \"treatment1 prediction\" : pred}).reset_index(drop = True)\n",
    "samp.to_csv(\"/data/log-data-2024/20241127_Final/8man_sample_20241127_predicted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "272aaaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samp = pd.read_csv(\"/data/log-data-2024/8man_sample_new.csv\")\n",
    "# samp = samp[[\"control\", \"treatment1\", \"treatment2\", \"treatment3\"]]\n",
    "# samp[\"treatment1 prediction\"] = pred\n",
    "# samp.to_csv(\"/data/log-data-2024/8man_sample_new_new.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
